{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105a598d-4eda-4188-9f24-d635b57ddedb",
   "metadata": {},
   "source": [
    "# Company Summarizer\n",
    "\n",
    "LLMs are great at structuring and summarizing unstructured data, such as natural language. We can leverage LLMs to extract specific information from text content, such as websites.\n",
    "\n",
    "Imagine you are hunting for a job, but you are searching for a specific traits in companies, such as an innovative culture that embraces experimentation. Or you want an instant overview of tech-related positions that can currently be found on the company page. LLMs are perfect for such tasks. They make automization of extracting information from natural language super easy. And they are really good at it, too.\n",
    "\n",
    "In this project, I am using the OpenAI API to ask LLMs to extract and structure specific data from company websites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad72f8c3-90a3-4170-8846-4b7dd874d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import openai\n",
    "import requests\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be4b50f-66f6-4cb5-a624-10acf2cead66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    body: str\n",
    "    text: str\n",
    "    links: List[str]\n",
    "    \n",
    "    def __init__(url: str):\n",
    "        self.url = url\n",
    "\n",
    "    def __scrape_webpage(self):\n",
    "        response = requests.get(self.url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.__get_website_title(soup)\n",
    "        self.__get_website_text(soup)\n",
    "        self.__get_links_from_website(soup)\n",
    "\n",
    "    def __get_website_title(self, soup: BeautifulSoup):\n",
    "        self.title = soup.title.string if soup.title else \"Website has no title\"\n",
    "        \n",
    "    def __get_website_text(self, soup: BeautifulSoup):\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "            \n",
    "    def __get_links_from_website(soup: BeautifulSoup):\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb3f73-4310-49e5-8cf9-812351b270fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
